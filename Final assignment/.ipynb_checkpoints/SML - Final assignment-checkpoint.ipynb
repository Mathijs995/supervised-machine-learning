{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supervised Machine Learning - Final Assignment**\n",
    "[Mathijs de Jong (380891)](mailto:m.de.jong@tinbergen.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Environment Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initialize notebook settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Initialize notebook settings\n",
    "################################################################################\n",
    "\n",
    "# Install and upgrade required Python packages\n",
    "!pip -q install pip rpy2 --upgrade\n",
    "\n",
    "# Load R support into Jupyter notebook\n",
    "import rpy2\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Initialize R environment settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "################################################################################\n",
    "# Initialize R environment settings\n",
    "################################################################################\n",
    "\n",
    "# Initialize working directory\n",
    "BASE.DIR = '/Users/mathijs/Google Drive/Tinbergen - MPhil'\n",
    "setwd(paste0(BASE.DIR, '/Supervised Machine Learning/Final assignment'))\n",
    "\n",
    "# Specify printing settings and set seed\n",
    "options(scipen=999)\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importing R dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "################################################################################\n",
    "# Load dependencies\n",
    "################################################################################\n",
    "\n",
    "# Install public packages\n",
    "install.packages(setdiff(c('censReg', 'caret', 'devtools', 'doParallel',\n",
    "  'lmtest', 'randomForest', 'rpart', 'sampleSelection', 'sandwich'),\n",
    "  installed.packages()), verbose=F, quiet=T,\n",
    "  repos='https://mirror.lyrahosting.com/CRAN/')\n",
    "\n",
    "# Install and load latest version of own (mlkit) package\n",
    "devtools::install_github('Accelerytics/mlkit', upgrade='always', force=T,\n",
    "  quiet=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "################################################################################\n",
    "# Pre-process data\n",
    "################################################################################\n",
    "\n",
    "# Load and pre-process \n",
    "df.raw = readxl::read_excel(\"dataset13.xlsx\")\n",
    "df = df.raw[df.raw$mail == 1, ]\n",
    "\n",
    "# Update and add new explanatory variables\n",
    "for (i in nrow(df))\n",
    "  if (df[i, 'mailid'] != 7) df[i, 'lastresp'] = df[i - 1, 'resp']\n",
    "\n",
    "N.all = nrow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Specify models\n",
    "y.amount = ifelse(df$amount > 0, log(df$amount), 0)\n",
    "y.resp = df$resp\n",
    "form = formula(amount ~ 1 + lastresp + avresp + avamount + urblvl + hhsize\n",
    "  + lowinc + highinc)\n",
    "select.form = formula(resp ~ 1 + lastresp + avresp + urblvl + hhsize\n",
    "  + lowinc + highinc)\n",
    "amount.form = formula(amount ~ 1 + lastresp + avamount + urblvl + hhsize\n",
    "  + lowinc + highinc)\n",
    "\n",
    "# Create train, develop and test sets\n",
    "train.ids = \n",
    "dev.ids = \n",
    "test.ids = \n",
    "\n",
    "x = model.matrix(form, data=df)\n",
    "x.select = model.matrix(select.form, data=df)\n",
    "x.amount = model.matrix(amount.form, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Benchmark Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Benchmark: Tobit I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "censReg::censReg(formula = form, left = 0, right = Inf, data = df)\n",
      "\n",
      "Observations:\n",
      "         Total  Left-censored     Uncensored Right-censored \n",
      "         46163          28486          17677              0 \n",
      "\n",
      "Coefficients:\n",
      "              Estimate Std. error t value              Pr(> t)    \n",
      "(Intercept) -32.800926   3.582929  -9.155 < 0.0000000000000002 ***\n",
      "lastresp     -4.388837   0.423768 -10.357 < 0.0000000000000002 ***\n",
      "avresp        0.309710   0.006084  50.903 < 0.0000000000000002 ***\n",
      "avamount      0.404889   0.007632  53.050 < 0.0000000000000002 ***\n",
      "urblvl        0.137276   0.104208   1.317             0.187729    \n",
      "hhsize       -0.013356   0.732363  -0.018             0.985450    \n",
      "lowinc        0.095831   0.044138   2.171             0.029919 *  \n",
      "highinc       0.118516   0.034898   3.396             0.000684 ***\n",
      "logSigma      3.209859   0.005910 543.126 < 0.0000000000000002 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Newton-Raphson maximisation, 7 iterations\n",
      "Return code 2: successive function values within tolerance limit\n",
      "Log-likelihood: -95564.23 on 9 Df\n",
      "\n",
      " (Intercept)     lastresp       avresp     avamount       urblvl       hhsize \n",
      "-32.80092552  -4.38883710   0.30970954   0.40488924   0.13727583  -0.01335583 \n",
      "      lowinc      highinc     logSigma \n",
      "  0.09583061   0.11851620   3.20985857 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "################################################################################\n",
    "# Benchmark model - Tobit I\n",
    "################################################################################\n",
    "\n",
    "# Tobit I - MLE using censReg package\n",
    "censReg.tobit1 = censReg::censReg(form, left=0, right=Inf, data=df)\n",
    "print(summary(censReg.tobit1))\n",
    "\n",
    "# Tobit I - MLE using own implementation\n",
    "tobit1_log_likelihood = function(theta, y, x) {\n",
    "  length.theta = length(theta)\n",
    "  sigma = exp(theta[length.theta])\n",
    "  x.beta = x %*% theta[1:(length.theta - 1)]\n",
    "  return(sum(!y * pnorm(-x.beta / sigma, log.p=T) - (y > 0) * (0.5 * log(2 * pi)\n",
    "    + log(sigma) + ((y - x.beta) ^ 2) / (2 * sigma ^ 2))))\n",
    "}\n",
    "theta0 = censReg.tobit1$estimate\n",
    "ml.tobit1 = optim(\n",
    "  par = theta0,\n",
    "  fn = function(theta) return(-tobit1_log_likelihood(theta, y.amount, x))\n",
    ")\n",
    "print(ml.tobit1$par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Benchmark: Tobit II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Tobit 2 model (sample selection model)\n",
      "2-step Heckman / heckit estimation\n",
      "46163 observations (28486 censored and 17677 observed)\n",
      "17 free parameters (df = 46147)\n",
      "Probit selection equation:\n",
      "                      Estimate Std. Error t value             Pr(>|t|)    \n",
      "x.select(Intercept) -1.3974933  0.1620550  -8.624 < 0.0000000000000002 ***\n",
      "x.selectlastresp    -0.2033947  0.0189264 -10.747 < 0.0000000000000002 ***\n",
      "x.selectavresp       0.0184140  0.0002605  70.684 < 0.0000000000000002 ***\n",
      "x.selecturblvl      -0.0072820  0.0047415  -1.536              0.12459    \n",
      "x.selecthhsize       0.0041912  0.0332783   0.126              0.89978    \n",
      "x.selectlowinc       0.0057073  0.0020044   2.847              0.00441 ** \n",
      "x.selecthighinc      0.0050809  0.0015857   3.204              0.00135 ** \n",
      "Outcome equation:\n",
      "                      Estimate Std. Error t value             Pr(>|t|)    \n",
      "x.amount(Intercept)  1.7040338  0.1097294  15.529 < 0.0000000000000002 ***\n",
      "x.amountlastresp     0.0034845  0.0112186   0.311                0.756    \n",
      "x.amountavamount     0.0289151  0.0002447 118.160 < 0.0000000000000002 ***\n",
      "x.amounturblvl       0.0263885  0.0031641   8.340 < 0.0000000000000002 ***\n",
      "x.amounthhsize      -0.0185219  0.0217725  -0.851                0.395    \n",
      "x.amountlowinc       0.0011111  0.0013325   0.834                0.404    \n",
      "x.amounthighinc      0.0071325  0.0010471   6.812     0.00000000000975 ***\n",
      "Multiple R-Squared:0.4593,\tAdjusted R-Squared:0.4591\n",
      "   Error terms:\n",
      "              Estimate Std. Error t value            Pr(>|t|)    \n",
      "invMillsRatio  0.33852    0.01502   22.54 <0.0000000000000002 ***\n",
      "sigma          0.58247         NA      NA                  NA    \n",
      "rho            0.58118         NA      NA                  NA    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "Tobit 2 model (sample selection model)\n",
      "Maximum Likelihood estimation\n",
      "Newton-Raphson maximisation, 5 iterations\n",
      "Return code 2: successive function values within tolerance limit\n",
      "Log-Likelihood: -39530.63 \n",
      "46163 observations (28486 censored and 17677 observed)\n",
      "16 free parameters (df = 46147)\n",
      "Probit selection equation:\n",
      "                      Estimate Std. Error t value             Pr(>|t|)    \n",
      "x.select(Intercept) -1.4090974  0.1620858  -8.694 < 0.0000000000000002 ***\n",
      "x.selectlastresp    -0.2226717  0.0187279 -11.890 < 0.0000000000000002 ***\n",
      "x.selectavresp       0.0187944  0.0002574  73.027 < 0.0000000000000002 ***\n",
      "x.selecturblvl      -0.0071992  0.0047356  -1.520              0.12847    \n",
      "x.selecthhsize       0.0051778  0.0332894   0.156              0.87640    \n",
      "x.selectlowinc       0.0056957  0.0020039   2.842              0.00448 ** \n",
      "x.selecthighinc      0.0049406  0.0015858   3.116              0.00184 ** \n",
      "Outcome equation:\n",
      "                      Estimate Std. Error t value             Pr(>|t|)    \n",
      "x.amount(Intercept)  1.8960103  0.1060623  17.876 < 0.0000000000000002 ***\n",
      "x.amountlastresp    -0.0704290  0.0095743  -7.356    0.000000000000193 ***\n",
      "x.amountavamount     0.0282619  0.0002416 116.963 < 0.0000000000000002 ***\n",
      "x.amounturblvl       0.0276001  0.0030837   8.950 < 0.0000000000000002 ***\n",
      "x.amounthhsize      -0.0145199  0.0211985  -0.685                0.493    \n",
      "x.amountlowinc       0.0005576  0.0012983   0.429                0.668    \n",
      "x.amounthighinc      0.0068595  0.0010200   6.725    0.000000000017730 ***\n",
      "   Error terms:\n",
      "      Estimate Std. Error t value            Pr(>|t|)    \n",
      "sigma 0.543980   0.003597  151.24 <0.0000000000000002 ***\n",
      "rho   0.346903   0.017031   20.37 <0.0000000000000002 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "--------------------------------------------\n",
      "\n",
      "t test of coefficients:\n",
      "\n",
      "                             Estimate Std. Error t value              Pr(>|t|)\n",
      "x.amount[ids, ](Intercept)  1.7114653  0.1064529 16.0772 < 0.00000000000000022\n",
      "x.amount[ids, ]lastresp     0.0018611  0.0109987  0.1692                0.8656\n",
      "x.amount[ids, ]avamount     0.0288235  0.0018451 15.6213 < 0.00000000000000022\n",
      "x.amount[ids, ]urblvl       0.0263426  0.0039135  6.7312      0.00000000001735\n",
      "x.amount[ids, ]hhsize      -0.0167802  0.0197650 -0.8490                0.3959\n",
      "x.amount[ids, ]lowinc       0.0010218  0.0012633  0.8089                0.4186\n",
      "x.amount[ids, ]highinc      0.0069197  0.0011349  6.0974      0.00000000110081\n",
      "inv.mills[ids]              0.3384348  0.0253793 13.3350 < 0.00000000000000022\n",
      "                              \n",
      "x.amount[ids, ](Intercept) ***\n",
      "x.amount[ids, ]lastresp       \n",
      "x.amount[ids, ]avamount    ***\n",
      "x.amount[ids, ]urblvl      ***\n",
      "x.amount[ids, ]hhsize         \n",
      "x.amount[ids, ]lowinc         \n",
      "x.amount[ids, ]highinc     ***\n",
      "inv.mills[ids]             ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "       estimate\n",
      "sigma 0.5787111\n",
      "rho   0.5848078\n",
      "               sigma                  rho x.select.(Intercept) \n",
      "         0.578711146          0.584807798         -1.397493683 \n",
      "   x.select.lastresp      x.select.avresp      x.select.urblvl \n",
      "        -0.203394582          0.018413967         -0.007281806 \n",
      "     x.select.hhsize      x.select.lowinc     x.select.highinc \n",
      "         0.004191090          0.005707299          0.005080880 \n",
      "x.amount.(Intercept)    x.amount.lastresp    x.amount.avamount \n",
      "         1.711465343          0.001861084          0.028823510 \n",
      "     x.amount.urblvl      x.amount.hhsize      x.amount.lowinc \n",
      "         0.026342607         -0.016780179          0.001021845 \n",
      "    x.amount.highinc \n",
      "         0.006919738 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "################################################################################\n",
    "# Benchmark model - Tobit II\n",
    "################################################################################\n",
    "\n",
    "# Tobit II - Heckman Two-Step Procedure using sampleSelection package\n",
    "two.step.tobit2.res = sampleSelection::selection(\n",
    "  y.resp ~ 0 + x.select,\n",
    "  y.amount ~ 0 + x.amount,\n",
    "  method='2step'\n",
    ")\n",
    "print(summary(two.step.tobit2.res))\n",
    "\n",
    "# Tobit II - MLE using sampleSelection package\n",
    "ml.tobit2.res = sampleSelection::selection(\n",
    "  y.resp ~ 0 + x.select,\n",
    "  y.amount ~ 0 + x.amount,\n",
    "  method='ml'\n",
    ")\n",
    "print(summary(ml.tobit2.res))\n",
    "\n",
    "# Tobit II - Heckman Two-Step Procedure using own implementation\n",
    "select.probit = glm(y.resp ~ 0 + x.select, family=binomial(link=\"probit\"))\n",
    "summary(select.probit)\n",
    "x.beta.select = x.select %*% select.probit$coefficients\n",
    "inv.mills = dnorm(x.beta.select) / pnorm(x.beta.select)\n",
    "ids = y.amount != 0\n",
    "amount.res = lm(y.amount[ids] ~ 0 + x.amount[ids, ] + inv.mills[ids])\n",
    "print(lmtest::coeftest(amount.res, vcov=sandwich::vcovHC(amount.res,\n",
    "  type=\"HC0\")))\n",
    "eta = amount.res$residuals\n",
    "sigma12 = amount.res$coefficients[length(amount.res$coefficients)]\n",
    "sigma22 = sum(eta ^ 2 + sigma12 ^ 2 * inv.mills[ids] * (x.beta.select[ids]\n",
    "  + inv.mills[ids])) / (sum(ids) - 1)\n",
    "sqrt.sigma22 = sqrt(sigma22)\n",
    "rho = sigma12 / sqrt.sigma22\n",
    "res.df = data.frame('estimate' = c(sqrt.sigma22, rho))\n",
    "rownames(res.df) = c('sigma', 'rho')\n",
    "print(res.df)\n",
    "\n",
    "# Tobit II - MLE using own implementation\n",
    "theta0 = c(sqrt.sigma22, rho, select.probit$coefficients,\n",
    "  amount.res$coefficients[1:ncol(x.amount)])\n",
    "names(theta0) = c('sigma', 'rho', paste0('x.select.', colnames(x.select)),\n",
    "  paste0('x.amount.', colnames(x.amount)))\n",
    "\n",
    "tobit2_log_likelihood = function(theta, y, x.select, x.amount) {\n",
    "  sigma = theta[1]\n",
    "  rho = theta[2]\n",
    "  d = (y == 0)\n",
    "  k.select = ncol(x.select)\n",
    "  x.beta.select = x.select %*% theta[3:(2 + k.select)]\n",
    "  x.beta.amount = x.amount %*% theta[(3 + k.select):length(theta)]\n",
    "  return(sum(!d * pnorm(-x.beta.select, log.p=T) + d * pnorm(x.beta.select\n",
    "    + rho / sigma * (y - x.beta.amount) / sqrt(1 - rho ^ 2), log.p=T)\n",
    "    - 0.5 * log(2 * pi) - log(sigma) - ((y - x.beta.amount) ^ 2\n",
    "    / (2 * sigma ^ 2))))\n",
    "}\n",
    "\n",
    "ml.tobit2 = optim(\n",
    "  par = theta0,\n",
    "  fn = function(theta) return(-tobit2_log_likelihood(theta, y.amount, x.select,\n",
    "  x.amount))\n",
    ")\n",
    "print(ml.tobit2$par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Two-Part Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "cl = parallel::makePSOCKcluster(5)\n",
    "doParallel::registerDoParallel(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "classifier.ctrl = caret::trainControl(\n",
    "  method = 'cv',\n",
    "  number = 5,\n",
    "  search = 'grid'\n",
    ")\n",
    "\n",
    "regression.ctrl = caret::trainControl(\n",
    "  method = 'cv',\n",
    "  number = 5,\n",
    "  search = 'grid'\n",
    ")\n",
    "\n",
    "mixed.ctrl = caret::trainControl(\n",
    "  method = 'cv',\n",
    "  number = 5,\n",
    "  search = 'grid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "classifiers = list(\n",
    "  glm.logit = list(\n",
    "    method = 'glm',\n",
    "    grid = NULL,\n",
    "    args = list(family = 'binomial(link=\"logit\")')\n",
    "  ),\n",
    "  'glm.probit' = list(\n",
    "    method = 'glm',\n",
    "    grid = NULL,\n",
    "    args = list(family = 'binomial(link=\"gaussian\")')\n",
    "  ), \n",
    "  'svm.linear' = list(method='lssvmLinear', grid=expand.grid(\n",
    "    tau = c(0, 1, 2, 3)\n",
    "  )),\n",
    "  'svm.poly' = list(method='lssvmPoly', grid=expand.grid(\n",
    "    degree = c(),\n",
    "    scale = c(),\n",
    "    tau = c()\n",
    "  )),\n",
    "  'svm.radial' = list(method='lssvmRadial', grid=expand.grid(\n",
    "    sigma = c(),\n",
    "    tau = c()\n",
    "  )),\n",
    "  'tree.adaboost' = list(method='adaboost', grid=expand.grid(\n",
    "    nIter = c(),\n",
    "    method = c()\n",
    "  )),\n",
    "  'tree.logitBoost' = list(method='LogitBoost', grid=expand.grid(\n",
    "    nIter = c()\n",
    "  )),\n",
    "  'tree.gbm' = list(method='gbm', grid=expand.grid(\n",
    "    n.trees = c(),\n",
    "    iteraction.depth = c(),\n",
    "    shrinkage = c(),\n",
    "    n.minobsinnode = c()\n",
    "  ))\n",
    ")\n",
    "\n",
    "# regression.models = list(\n",
    "#   'glm.net' : list(method='glmnet', c(alpha, lambda)),\n",
    "#   'krr.poly' : list(method='krlsPoly', c(lambda, degree)),\n",
    "#   'krr.radial' : list(method='krlsRadial', c(lambda, sigma))\n",
    "#   'cart.standard' : list(method='rpart', c(cp))\n",
    "#   'xgboost.linear' : list(method='xgbLinear', c(nrounds, lambda, alpha, eta))\n",
    "#   'xgboost.tree' : list(method='xgbTree', c(nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample))\n",
    "# )\n",
    "\n",
    "# mixed.models = list(\n",
    "#   'xgboost.linear' : list(method='xgbLinear', c(nrounds, lambda, alpha, eta))\n",
    "#   'xgboost.tree' : list(method='xgbTree', c(nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From cffi callback <function _processevents at 0x7f8583fda040>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mathijs/tinbergen/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 270, in _processevents\n",
      "    try:\n",
      "KeyboardInterrupt\n",
      "From cffi callback <function _processevents at 0x7f8583fda040>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mathijs/tinbergen/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 270, in _processevents\n",
      "    try:\n",
      "KeyboardInterrupt\n",
      "From cffi callback <function _processevents at 0x7f8583fda040>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mathijs/tinbergen/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 270, in _processevents\n",
      "    try:\n",
      "KeyboardInterrupt\n",
      "From cffi callback <function _processevents at 0x7f8583fda040>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mathijs/tinbergen/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 270, in _processevents\n",
      "    try:\n",
      "KeyboardInterrupt\n",
      "From cffi callback <function _processevents at 0x7f8583fda040>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mathijs/tinbergen/lib/python3.8/site-packages/rpy2/rinterface_lib/callbacks.py\", line 270, in _processevents\n",
      "    try:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "params.length = 3\n",
    "params.list = list(\n",
    "  lambda = 2 ^ seq(5, -5, length.out = 10),\n",
    "  kernel = c(kernlab::vanilladot, kernlab::polydot, kernlab::rbfdot),\n",
    "  kernel.offset = 1,\n",
    "  kernel.degree = c(0.5, 2, 3),\n",
    "  kernel.sigma = c(0.5, 1, 2),\n",
    "  kernel.scale = 1,\n",
    "  hinge = c('absolute', 'quadratic', 'huber'),\n",
    "  hinge.delta = c(0.5, 2, 3)\n",
    ")\n",
    "\n",
    "# Specify fold ids\n",
    "N = nrow(df)\n",
    "n.folds = 3\n",
    "fold.id = ((1:N) %% n.folds + 1)[sample(N, N)]\n",
    "\n",
    "# Define metric functions\n",
    "miss.rate = function(y.hat, y) sum(y != ifelse(y.hat >= 0, 1L, -1L)) / length(y)\n",
    "\n",
    "# Grid search 3-fold cross-validation\n",
    "gscv.svm = mlkit::grid.search.cross.validation(select.form, df, SVMMaj::svmmaj,\n",
    "  params.list, ind.metric=miss.rate, fold.id=fold.id, force=T, verbose=T,\n",
    "  use.formula=F, scale='zscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in y[, \"time\"] : subscript out of bounds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in y[, \"time\"] : subscript out of bounds\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "train.classifiers = function(classifiers, df.train, form, df.test=df.train) {\n",
    "  dep.var = all.vars(form)[1]\n",
    "  y.train = ifelse(df.train[, dep.var] > 0, 1L, 0L)\n",
    "  \n",
    "  for (classifier in names(classifiers)) {\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifiers[[classifier]][['model']] = caret::train(\n",
    "      x = model.matrix(form, df.train),\n",
    "      y = y.train,\n",
    "      method = classifiers[[classifier]][['method']],\n",
    "#       ... = classifiers[[classifier]][['args']],\n",
    "      metric = 'Accuracy'\n",
    "#       trControl = classifier.ctrl,\n",
    "#       tuneGrid = classifiers[[classifier]][['grid']]\n",
    "    )\n",
    "\n",
    "    # Extract the performance metrics on the test data and store them\n",
    "#     classifiers[[classifier]][['metrics']] = caret::confusionMatrix(\n",
    "#       data = predict(\n",
    "#         classifiers[[classifier]][['model']],\n",
    "#         newdata = model.matrix(form, df.test)\n",
    "#       ),\n",
    "#       reference = df.test[, dep.var],\n",
    "#       mode = \"prec_recall\"\n",
    "#     )\n",
    "  }\n",
    "  return(classifiers)\n",
    "}\n",
    "\n",
    "classifiers = train.classifiers(classifiers, df, select.form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Binary Classifier: Probit Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Binary Classifier: Logit Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Binary Classifier: Support Vector Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Binary Classifier: Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Binary Classifier: Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Binary Classifier: AdaBoost.M1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "################################################################################\n",
    "# Two-Part Models - Classifiers\n",
    "################################################################################\n",
    "\n",
    "# Logit Classifier\n",
    "select.logit = glm(y.resp ~ 0 + x.select, family=binomial(link=\"logit\"))\n",
    "\n",
    "# SVM\n",
    "# Specify hyperparameter values to consider\n",
    "params.length = 3\n",
    "params.list = list(\n",
    "  lambda = 2 ^ seq(5, -5, length.out = 10),\n",
    "  kernel = c(kernlab::vanilladot, kernlab::polydot, kernlab::rbfdot),\n",
    "  kernel.offset = 1,\n",
    "  kernel.degree = c(0.5, 2, 3),\n",
    "  kernel.sigma = c(0.5, 1, 2),\n",
    "  kernel.scale = 1,\n",
    "  hinge = c('absolute', 'quadratic', 'huber'),\n",
    "  hinge.delta = c(0.5, 2, 3)\n",
    ")\n",
    "\n",
    "# Specify fold ids\n",
    "N = nrow(df.train); n.folds = 3; fold.id = ((1:N) %% n.folds + 1)[sample(N, N)]\n",
    "\n",
    "################################################################################\n",
    "# Hyperparameter tuning\n",
    "################################################################################\n",
    "\n",
    "# Define metric functions\n",
    "miss.rate = function(y.hat, y) sum(y != ifelse(y.hat >= 0, 1L, -1L)) / length(y)\n",
    "\n",
    "# Grid search 3-fold cross-validation\n",
    "gscv.svm = grid.search.cross.validation(formula, df.train, SVMMaj::svmmaj,\n",
    "                                        params.list, ind.metric=mis.rate, fold.id=fold.id, force=T, verbose=T,\n",
    "                                        use.formula=F, scale='zscore')\n",
    "\n",
    "res = SVMMaj::svmmaj(X.train, y.train, lambda = 14, scale='zscore',\n",
    "                     hinge='quadratic')\n",
    "pred = predict(res, X.test)\n",
    "  \n",
    "# Decision tree\n",
    "select.tree = rpart::rpart(select.form, data=df,\n",
    "  control=rpart::rpart.control(cp=0.00001))\n",
    "\n",
    "# Random forest\n",
    "randomForest::randomForest(select.form, data=df, mtry = 3, ntree = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regression: Elastic Net Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regression: Kernel Ridge Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regression: CART**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regression: Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regression: XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Direct Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Censored Regression: Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Censored Regression: Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Censored Regression: XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Two-Part Models - Mixed\n",
    "################################################################################\n",
    "\n",
    "# Decision tree\n",
    "select.tree = rpart::rpart(y.amount ~ 0 + x, control=rpart::rpart.control(\n",
    "  cp=0.00001))\n",
    "\n",
    "# Random forest\n",
    "randomForest::randomForest(y.amount ~ 0 + x, mtry = 3, ntree = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "parallel::stopCluster(cl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
